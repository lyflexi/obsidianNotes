# 五层协议体系结构
OSI 与 TCP/IP 各层的结构与功能, 都有哪些协议?

![[Pasted image 20240131152634.png]]
而学习计算机网络时我们一般采用折中的办法，也就是中和 OSI 和 TCP/IP 的优点，采用一种只有五层协议的体系结构，这样既简洁又能将概念阐述清楚。从上到下分别是应用层，运输层，网络层，数据链路层，物理层

- 应用层(application-layer）的任务是通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程间（进程：主机中正在运行的程序）的通信和交互的规则。我们把应用层交互的数据单元称为报文。在互联网中应用层协议很多。如
	- 如域名系统 DNS，域名系统(Domain Name System 缩写 DNS，Domain Name 被译为域名)是因特网的一项核心服务，它作为可以将域名和 IP 地址相互映射的一个分布式数据库，能够使人更方便的访问互联网，而不用去记住能够被机器直接读取的 IP 数串。
	- 支持万维网应用的 HTTP 协议。超文本传输协议（HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议。所有的 WWW（万维网） 文件都必须遵守这个标准。设计 HTTP 最初的目的是为了提供一种发布和接收 HTML 页面的方法。（百度百科）
	- 支持电子邮件的 SMTP 协议等等。
- 运输层(transport layer)的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务。应用进程利用该服务传送应用层报文。运输层主要使用以下两种协议:
	- 传输控制协议 TCP（Transmission Control Protocol）--提供面向连接的，可靠的数据传输服务。
	- 用户数据协议 UDP（User Datagram Protocol）--提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）。
- 网络层，在计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点， 确保数据及时传送。 在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。互联网是由大量的异构（heterogeneous）网络通过路由器（router）相互连接起来的。
	- 无连接的网际协议（Internet Protocol），因此互联网的网络层也叫做网际层或IP 层。
	- 许多路由选择协议。
- 数据链路层(data link layer)通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。
	- 在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息如：同步信息、地址信息息、差错控制等。
	- 在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提出数据部分，上交给网络层。 控制信息还使接收端能够检测到所收到的帧中有无差错。如果发现差错，数据链路层就简单地丢弃这个出了差错的帧，以避免继续在网络中传送下去白白浪费网络资源。如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用可靠性传输协议来纠正出现的差错。这种方法会使链路层的协议复杂些。
- 物理层，在物理层上所传送的数据单位是比特。物理层(physical layer)的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异， 使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。
# 一、应用层细述
## URI和URL
URI 的作用像身份证号一样，URL 的作用更像家庭住址一样。URL 是一种具体的 URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。

- URI(Uniform Resource Identifier) 是统一资源标志符，可以唯一标识一个资源。
    
- URL(Uniform Resource Locator) 是统一资源定位符，可以提供该资源的路径。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。
## HTTP如何保存用户信息

HTTP 是一种不保存状态，即无状态（stateless）协议。也就是说 HTTP 协议自身不对请求和响应之间的通信状态进行保存。那么我们保存用户状态呢？Session 机制的存在就是为了解决这个问题，Session 的主要作用就是通过服务端记录用户的状态。典型的场景是购物车，当你要添加商品到购物车的时候，服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了（一般情况下，服务器会在一定时间内保存这个 Session，过了时间限制，就会销毁这个 Session）。

在服务端保存 Session 的方法很多，最常用的就是内存和数据库(比如是使用内存数据库 redis 保存)。

既然 Session 存放在服务器端，那么客户端如何实现 Session 跟踪呢？

大部分情况下，我们都是通过在 Cookie 中附加一个 Session ID 来方式来跟踪。

客户端Cookie 被禁用怎么办?最常用的就是利用 URL 重写把 Session ID 直接附加在 URL 路径的后面。
![[Pasted image 20240131153737.png]]
## HTTP1.1
HTTP1.0 最早在网页中使用是在 1996 年，那个时候只是使用一些较为简单的网页上和网络请求上，而 HTTP1.1 则在 1999 年才开始广泛应用于现在的各大浏览器网络请求中，同时 HTTP1.1 也是当前使用最为广泛的 HTTP 协议。 主要区别主要体现在：
1. 长连接 : 在 HTTP/1.0 中，默认使用的是短连接，也就是说每次请求都要重新建立一次连接。HTTP 是基于 TCP/IP 协议的,每一次建立或者断开连接都需要三次握手四次挥手的开销，如果每次请求都要这样的话，开销会比较大。因此最好能维持一个长连接，可以用个长连接来发多个请求。HTTP 1.1 起，默认使用长连接 ,默认开启 Connection： keep-alive。 HTTP/1.1 的持续连接有非流水线方式和流水线方式 。
    1. 流水线方式是客户在收到 HTTP 的响应报文之前就能接着发送新的请求报文。
    2. 与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。
2. 错误状态响应码 :在 HTTP1.1 中新增了 24 个错误状态响应码，如 409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。
3. 缓存处理 :在 HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。
4. 带宽优化及网络连接的使用 :HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

### 长连接

在 `HTTP/1.0` 中默认使用短连接。也就是说，客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个 HTML 或其他类型的 Web 页中包含有其他的 Web 资源（如 JavaScript 文件、图像文件、CSS 文件等），每遇到这样一个 Web 资源，浏览器就会重新建立一个 HTTP 会话。

而从 `HTTP/1.1 起`，默认使用长连接，用以保持连接特性。使用长连接的 HTTP 协议，会在响应头加入这行代码：

```Java
Connection:keep-alive 
```

在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输 HTTP 数据的 TCP 连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive 不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如 Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。

早期 HTTP/1.0 性能上的一个很大的问题，那就是每发起一个请求，都要新建一次 TCP 连接（三次握手），而且是串行请求，做了无谓的 TCP 连接建立和断开，增加了通信开销。为了解决上述 TCP 连接问题，HTTP/1.1 提出了长连接的通信方式，也叫持久连接。这种方式的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。持久连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。
![[Pasted image 20240131154020.png]]
当然，如果某个 HTTP 长连接超过一定时间没有任何数据交互，服务端就会主动断开这个连接。

### 新增状态码
在 HTTP1.1 中新增了 24 个错误状态响应码，
- 如 409（Conflict）表示请求的资源与资源的当前状态发生冲突；
- 410（Gone）表示服务器上的某个资源被永久性的删除。
![[Pasted image 20240131154025.png]]
### 新增缓存处理策略

HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准

HTTP1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。

### 新增带宽优化策略

HTTP1.0 中，存在一些浪费带宽的现象：
- 例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，
- 并且不支持断点续传功能

HTTP1.1 则在请求头引入了 range 头域：
- 它允许只请求资源的某个部分，
- 返回码是 206（Partial Content）
- 方便了开发者自由的选择以便于充分利用带宽和连接。
## HTTP反向代理
正向代理(Proxy)在网络上是用来代理客户端(Client)的，而反向代理(Reverse Proxy)在网络上是用来代理[服务端](https://www.zhihu.com/search?q=%E6%9C%8D%E5%8A%A1%E7%AB%AF&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2771833737%7D)(Server)的。

通常情况下，咱们作为客户端(Client)，访问网络上的资源，都是发送请求到互联网(Internet)，之后导向相应的服务端(Server)获取资源。这属于没有加任何代理的网络访问
![[Pasted image 20240131154447.png]]

### 正向代理Proxy

正向代理(Proxy)，就是指在Client和Internet之间加一个中间服务，这个服务作为Client的代理人，拦截所有Client发出去的通讯，以代理人的身份再统一发出，从而代表Client和Internet进行交流，避免Client和Internet的直接交流。
![[Pasted image 20240131154508.png]]

正向代理(Proxy)

这样加上一个正向代理(Proxy)的好处是什么呢？
- Proxy可以隐藏Client的IP, 暴露出去只是Proxy自己的IP，从而保护Client的隐私安全。
- Proxy可以作为缓存，当有相同资源的请求时，可以直接返回缓存内容，提高响应速度。
- Proxy可以作为过滤，限制或者阻断访问Internet上面一些特定内容。

Proxy可以作为跳板(比如VPN)，科学上网

### 反向代理Reverse Proxy

反向代理(Reverse Proxy), 就是指在Internet和Web Server之间加上一个中间服务，这个服务作为Web Server的代理人，拦截所有发给Web Server的请求，然后再统一分发给代理的Web Servers, 避免Internet网络流量直接发给Web Server.
![[Pasted image 20240131154538.png]]

反向代理(Reverse Proxy)

这样加上一个反向代理(Reverse Proxy)有什么好处呢？
- ReverseProxy可以隐藏WebServerIP, 只有反向代理的IP暴露网络, 从而保护WebServer。
- ReverseProxy可以作为LoadBalancer，合理分配流量到集群里的WebServer。
- ReverseProxy可以作为网站静态内容的缓存，大大提高响应速度并减轻WebServer负担。
- ReverseProxy可以代为处理SSL加密(计算量较大)，减轻WebServer的负担。

#### 反向代理服务器Nginx

Nginx应该是最常见的反向代理服务器之一了，如果你从事Web相关的开发工作，一定对这个报错非常熟悉LOL。
![[Pasted image 20240131154555.png]]

#### API Gateway
ReverseProxy还有一个比较有意思的功能就是
在网络架构的工程实践上，如果一个私有网络想要访问其他网络的资源，那么一般需要给私有网络加上一个正向代理(Proxy)。如果一个私有网络想要被其他网络访问，那么一般需要给私有网络加上一个反向代理(Reverse Proxy)，或者API Gateway(本身也可以算作一种Reverse Proxy)。
![[Pasted image 20240131154632.png]]

#### GlobalServerLoadBalancer
ReverseProxy还有一个比较有意思的功能就是可以作为GlobalServerLoadBalancer，区别于普通的流量分配的LoadBalancer, GlobalServerLoadBalancer的作用更多是让不同地域的人访问网站会更快。大型网站(比如Netflix, Google, Amazon etc)，会在全世界各个地方部署ReverseProxy，然后把相应区域的流量导到地理位置更近的Web Server，从而提供更快速的响应服务。
![[Pasted image 20240131154609.png]]


为啥代理Client就是"正向"，而代理Server就是"反向"呢？其实是学术翻译的错误

我的猜测是这个正反方向是指的请求的方向：Client的代理请求是向外发出的，直观理解上可能更靠近正向；Server的代理请求是向内接收的，直观上理解可能更靠近反向。当然，这个也基本上属于个人推测......实际上这个也不重要。咱们只需要知道正向代理代理的是Client，反向代理代理的是Server就够了。
## HTTPS安全
HTTPS与Http的区别如下：
端口 ：HTTP 的 URL 由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443。
安全性：HTTP 协议运行在 TCP 之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS 是运行在 SSL/TLS 之上，SSL/TLS 运行在 TCP 之上。所以说，HTTP 安全性没有 HTTPS 高
资源消耗： HTTPS 比 HTTP 耗费更多服务器资源。

HTTPS的加密策略分为对称加密和非对称加密
- 对称加密【快】：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有 DES、AES 等；
- 非对称加密【慢】：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有 RSA、DSA 等。
### 非对称加密流程
非对称加密场景下的公私钥都是由服务器方生成的，先明确定义：
- 公钥：公开的密钥。
- 私钥：私有的密钥。
非对称公私钥可以双向加解密的，但前提是服务器自己保存绝密的私钥，只是把公钥公开。
1. 公钥加密私钥解密，称之为加密，也就是把明文变为加密文，只有接收者才能解读内容。原理很简单，需要通讯的时候接收者把公钥发给发送者，发送者用公钥加密，把秘文发给接受者，半路上被截获了也没用，因为要解密需要私钥，而私钥只有接收者有。
2. 私钥加密公钥解密，称之为签名。签名的目的是验证消息发送者的身份，杜绝伪造。因为私钥只有消息发送者有，所以只有发送者才能制造消息。因为是公钥，谁都可以解密，所以签名不是为了保密，而是为了验证身份。
#### 密钥对生成与公钥分发
想象这样一个场景：苏珊S给鲍勃B写信，鲍勃给苏珊回信。
该场景下，鲍勃就相当于服务器，因此鲍勃有两把钥匙，一把是公钥，另一把是私钥。

鲍勃把公钥送给他的朋友们----帕蒂、道格、苏珊----每人一把。（公钥不怕泄漏，要不怎么叫公钥）
![[Pasted image 20240131154920.png]]

#### 公钥加密，发送信件

苏珊要给鲍勃写一封保密的信。她写完后用鲍勃的公钥加密，就可以达到保密的效果。

鲍勃收信后，用私钥解密，就看到了信件内容。这里要强调的是，只要鲍勃的私钥不泄露，这封信就是安全的，即使落在别人手里，也无法解密。
![[Pasted image 20240131154932.png]]

#### 私钥加密，回复信件

鲍勃给苏珊回信，决定采用“数字签名”。他写完后先用Hash函数，生成信件的摘要（digest）。
![[Pasted image 20240131154937.png]]

然后，鲍勃使用私钥，对这个摘要加密，生成“数字签名”（signature）。
![[Pasted image 20240131154942.png]]
鲍勃将这个签名，附在信件下面，一起发给苏珊。
![[Pasted image 20240131154950.png]]

苏珊收信后，取下数字签名，用鲍勃的公钥解密，得到信件的摘要。由此证明，这封信确实是鲍勃发出的。
![[Pasted image 20240131154958.png]]

苏珊再对信件本身使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。如果两者一致，就证明这封信未被修改过。
![[Pasted image 20240131155004.png]]

#### 权威证书机构CA

复杂的情况出现了，公私钥成对的被掉包了：

道格想欺骗苏珊，他偷偷使用了苏珊的电脑，用自己的公钥换走了鲍勃的公钥。此时，苏珊实际拥有的是道格的公钥，但是还以为这是鲍勃的公钥。同时，道格冒充鲍勃用自己的私钥做成“数字签名”，写信给苏珊，让苏珊用假的鲍勃公钥进行解密。
![[Pasted image 20240131155009.png]]

后来，苏珊感觉不对劲，发现自己无法确定公钥是否真的属于鲍勃。她想到了一个办法，要求鲍勃去找“证书中心”（certificate authority，简称CA），为公钥做认证。证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成“数字证书”（Digital Certificate）。
![[Pasted image 20240131155013.png]]

鲍勃拿到数字证书以后，就可以放心了。以后再给苏珊写信，只要在签名的同时，再附上数字证书就行了。
![[Pasted image 20240131155018.png]]

苏珊收信后，用CA的公钥解开数字证书，就可以拿到鲍勃真实的公钥了，然后就能证明“数字签名”是否真的是鲍勃签的。
![[Pasted image 20240131155022.png]]

## 权威证书的典型应用场景Internet

下面，我们看一个应用"数字证书"的案例：==客户端向服务器请求公钥！！！，客户端利用权威证书，来确保服务器分发的公钥不会被掉包==

1. 首先，客户端向服务器发出加密请求。
![[Pasted image 20240131155028.png]]

2. 服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端。
    
![[Pasted image 20240131155033.png]]

3. 客户端（浏览器）的“证书管理器”，有“受信任的根证书颁发机构”列表。客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内。
    
![[Pasted image 20240131155037.png]]

4. 如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告。
![[Pasted image 20240131155042.png]]

5. 如果这张数字证书不是由受信任的机构颁发的，浏览器会发出另一种警告。
![[Pasted image 20240131155048.png]]

6. 如果数字证书是可靠的，客户端就可以使用证书中服务器提供的公钥，对信息进行加密，然后与服务器交换加密信息。
![[Pasted image 20240131155054.png]]
# 二、运输层细述
为什么需要 TCP 协议？ 

由于IP 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。

因此，如果需要保障网络数据包的可靠性，那么就需要由上层（传输层）的 TCP 协议来负责。

TCP 是面向连接的、可靠的、基于字节流的传输层通信协议，它能确保接收端接收的网络包是无损坏、无间隔、非冗余和按序的。
![[Pasted image 20240131162530.png]]

- 面向连接：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；
    
- 可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；
    
- 字节流：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。
## 瞧瞧 TCP 头格式

我们先来看看 TCP 头的格式，标注颜色的表示与本文关联比较大的字段，其他字段不做详细阐述。
![[Pasted image 20240131162229.png]]

- 序列号SeqNum：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。用来解决网络包乱序问题。
- 确认应答号ACKNum：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。用来解决丢包的问题。
- 除了SeqNum和ACKNum之外，TCP还有四个控制位：
	- ==ACK：该位为 1 时==，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 SYN 包之外该位必须设置为 1 。
	- RST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。
	- ==SYN：该位为 1 时==，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。
	- FIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。

## TCP建立连接-三次握手

TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而建立连接是通过三次握手来进行的。三次握手的过程如下图：
- 一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态
- 第一次握手：客户端会随机初始化序号（client_isn），同时把 SYN 标志位置为 1 表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态。
- 第二次握手：服务端收到客户端的 SYN 报文后，也是随机初始化自己的序号（server_isn），然后把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。
- 第三次握手：客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据。
最后客户端处于 ESTABLISHED 状态。
服务器收到客户端的应答报文后，也进入 ESTABLISHED 状态。
此时连接就已建立完成，客户端和服务端就可以相互发送数据了。
![[Pasted image 20240131162757.png]]
从上面的过程可以发现==第三次握手是可以携带数据的，前两次握手是不可以携带数据的==，这也是面试常问的题。

下面阐述为什么TCP建立连接要进行三次握手的原因
- 三次握手的首要原因是为了防止旧的初始化连接造成混乱。假设客户端连续发送多次建立连接的报文（SYN 以及序列号SeqNum），那么此时服务端就会回多个报文（ SYN + ACK 以及应答序列号ACKNum）给客户端；客户端收到后可以根据自身的上下文，就能够判断出哪些是服务器返回的历史连接（序列号过期或超时），那么客户端就会发送 RST 报文给服务端，表示中止这一次连接。客户端只响应，应答序列号为客户端当前序列号+1的最新连接
- 避免资源浪费，如果只有「两次握手」，当客户端的 SYN 请求连接在网络中阻塞，客户端没有接收到 ACK 报文，就会重新发送 SYN ，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的 ACK 确认信号，所以每收到一个 SYN 就只能先主动建立一个连接，那么服务器在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。
- 同步双方初始序列号，当客户端发送携带「初始序列号」的 SYN 报文的时候，需要服务端回一个 ACK 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，**这样一来一回，才能确保双方的初始序列号能被可靠的同步。**
## TCP断开连接-四次挥手
双方都可以主动断开连接，断开连接后主机中的「资源」将被释放，四次挥手的过程如下图：
- 客户端打算关闭连接，此时会发送一个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。
- 服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSED_WAIT 状态。客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。
- ==等待服务端处理完数据后，再向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。这是多了一次握手的关键==。因为服务器收到客户端的 FIN 报文时，仅仅表示客户端不再发送数据了但是还可能接收数据。所以服务端可以继续处理和发送数据，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。
- 客户端收到服务端的 FIN 报文后，回一个 ACK 应答报文，之后进入 TIME_WAIT 状态服务器收到了 ACK 应答报文后，就进入了 CLOSED 状态，至此服务端已经完成连接的关闭。客户端在经过 2MSL 一段时间后，自动进入 CLOSED 状态，至此客户端也完成连接的关闭。==这里一点需要注意是：主动关闭连接的一方，才有 TIME_WAIT 状态。==
![[Pasted image 20240131172043.png]]

TIME_WAIT为什么等于2MSL？什么是MSL

MSL与TTL：MSL 的单位是时间一般是30 秒，而 TTL 是经过路由跳数一般是 64跳，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经自然消失在网络中了。

TIME_WAIT 等于 2 倍的 MSL，比较合理的解释是：允许最后的ACK报文丢失一次，如果服务器方没有收到最后的 ACK 报文（1MSL），就会重发 FIN 报文（再次抵达客户端也要1MSL），因此一共2MSL

另外，客户端只要收到服务器发来的FIN之后，2MSL 时间将重新计时。

在 Linux 系统里 2MSL 默认是 60 秒，那么一个 MSL 也就是 30 秒。

如果要修改 TIME_WAIT 的时间长度，只能修改 Linux 内核代码里 TCP_TIMEWAIT_LEN 的值，并重新编译 Linux 内核。
```c
/* how long to wait to destroy TIME-WAIT state, about 60 seconds  */
#define TCP_TIMEWAIT_LEN (60*HZ) 
```


TIME_WAIT 过多有什么危害？过多的 TIME-WAIT 状态主要的危害有两种：
- 第一是内存资源占用；
- 第二是对端口资源的占用，一个 TCP 连接至少消耗「发起连接方」的一个本地端口；如果「发起连接方」的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。端口资源是有限的，因为端口就 65536 个，一般可以开启的端口为 32768～61000，也可以通过如下参数设置指定：
```shell
net.ipv4.ip_local_port_range 
```

理论上服务端可以建立很多连接，因为服务端只监听一个端口，不会因为 TCP 连接过多而导致端口资源受限。但是 TCP 连接过多，会占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等。

# 网络层细述
## 如何确定IP源地址
当客户端存在多个网卡时，在填写源地址 IP 时，就需要判断到底应该填写哪个地址。

这个判断相当于在多块网卡中判断应该使用哪个一块网卡来发送包。

这个时候就需要使用 `route -n` 命令查看当前系统的路由表，来判断哪一个网卡作为源地址 IP。
![[Pasted image 20240131173925.png]]

举个例子，根据上面的路由表，我们假设 Web 服务器的目标地址是 `192.168.10.200`，==判断源IP地址的规则是目标地址&源网卡掩码Genmask==

1. 目标地址&和网卡第一条目掩码Genmask，得到结果为 192.168.10.0，但是第一个条目的 Destination 是 192.168.3.0，两者不一致所以匹配失败。
2. 目标地址&和网卡第二条目掩码Genmask算，得到的结果为 192.168.10.0，与第二条目的 Destination 192.168.10.0 匹配成功，所以将使用 eth1 网卡的 IP 地址作为 IP 包头的源地址。
3. 第三条目比较特殊，它Destination和子网掩码都是 0.0.0.0，这表示默认网关，如果其他所有条目都无法匹配，就会自动匹配这一行。并且后续就由0.0.0.0把包发给路由器，此时源地址IP就是路由器的 IP 地址。
# 数据链路层细述..略
# 物理层细述..略