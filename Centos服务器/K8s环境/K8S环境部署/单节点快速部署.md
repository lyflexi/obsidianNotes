# ä¸€ã€ç¯å¢ƒå‡†å¤‡

```shell
å…³é—­é˜²ç«å¢™ï¼š
$ systemctl stop firewalld
$ systemctl disable firewalld

å…³é—­selinuxï¼š
$ sed -i 's/enforcing/disabled/' /etc/selinux/config 
$ setenforce 0

å…³é—­swapï¼š
sed -ri 's/.*swap.*/#&/' /etc/fstab

å°†æ¡¥æ¥çš„IPv4æµé‡ä¼ é€’åˆ°iptablesçš„é“¾ï¼š
cat > /etc/sysctl.d/k8s.conf << EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
$ sysctl --system
# åŠ è½½å†…æ ¸æ¨¡å—
modprobe br_netfilter
lsmod | grep br_netfilter
```

é‡å¯!

# äºŒã€dockerå®‰è£…

Kubernetesé»˜è®¤CRIï¼ˆå®¹å™¨è¿è¡Œæ—¶ï¼‰ä¸ºDockerï¼Œå› æ­¤å…ˆå®‰è£…Dockerã€‚

 1ã€è®¾ç½®yumæº
```shell
# base repo
cd /etc/yum.repos.d
mv CentOS-Base.repo CentOS-Base.repo.bak
curl -o CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
sed -i 's/gpgcheck=1/gpgcheck=0/g' /etc/yum.repos.d/CentOS-Base.repo

# docker repo
curl -o docker-ce.repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo

# k8s repo
cat > /etc/yum.repos.d/kubernetes.repo << EOF
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

# update cache
yum clean all  
yum makecache  
yum repolist
```

 2ã€å®‰è£…docker (å®‰è£…æ—¶æŒ‡å®šç‰ˆæœ¬å·)
```shell
# 1ã€æŸ¥çœ‹dockerç°æœ‰ç‰ˆæœ¬ å¹¶è¿›è¡Œæ’åº
yum list docker-ce --showduplicates | sort -r

# 2ã€æ ¹æ®éœ€è¦å®‰è£…æ‰€éœ€ç‰ˆæœ¬çš„docker
yum install docker-ce-19.03.9 docker-ce-cli-19.03.9 containerd.io -y

# 3ã€å¯åŠ¨docker å¹¶å°†å…¶è®¾ç½®æˆå¼€æœºè‡ªå¯
systemctl start docker
systemctl enabel docker

# 4ã€é…ç½®é•œåƒåŠ é€Ÿ
tee /etc/docker/daemon.json <<-'EOF'
{"registry-mirrors":["https://reg-mirror.qiniu.com/"]}
EOF
sudo systemctl daemon-reload
sudo systemctl restart docker

#Dockerä¸­å›½åŒºå®˜æ–¹é•œåƒ
https://registry.docker-cn.com
#ç½‘æ˜“
http://hub-mirror.c.163.com
#ustc 
https://docker.mirrors.ustc.edu.cn
```
# ä¸‰ã€å®‰è£…kubeadmã€kubeletå’Œkubectl(æ ¹æ®éœ€æ±‚ æŒ‡å®šç‰ˆæœ¬å· å¦‚æœä¸æŒ‡å®š é»˜è®¤æ‹‰å–æœ€æ–°çš„ç‰ˆæœ¬)

```shell
å®‰è£…kubeadmï¼Œkubeletå’Œkubectl

$ yum install -y kubelet kubeadm kubectl
$ systemctl enable kubelet

#å®‰è£…kubelet åä¼šåœ¨/etcä¸‹ç”Ÿæˆæ–‡ä»¶ç›®å½•/etc/kubernetes/manifests/
```

# å››ã€éƒ¨ç½²Kubernetes Master

åˆå§‹åŒ– ï¼ˆæˆ‘å½“å‰æ‹‰å–çš„k8sç‰ˆæœ¬ä¸º v1.20.5 ï¼‰

```shell
kubeadm init \
  --apiserver-advertise-address=`hostname -i` \
  --image-repository registry.aliyuncs.com/google_containers \
  --kubernetes-version v1.20.5 \
  --service-cidr=10.1.0.0/16 \
  --pod-network-cidr=10.244.0.0/16\
  --ignore-preflight-errors=NumCPU
```
![[Pasted image 20240131202420.png]]

åˆå§‹åŒ–æˆåŠŸåä¼šå‡ºç°å¦‚ä¸‹

```shell
Your Kubernetes control-plane has initialized successfully!

## å¦‚æœä½ å½“å‰ä¸æ˜¯rootç”¨æˆ· è¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ è´´åŠ ç¯å¢ƒå˜é‡
To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

## å¦‚æœä½ æ˜¯root ç”¨æˆ·,è¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ è´´åŠ ç¯å¢ƒå˜é‡
Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:
## å¦‚æœä½ æœ‰å…¶ä»–çš„ nodeèŠ‚ç‚¹éœ€è¦åŠ å…¥åˆ°é›†ç¾¤ä¸­æ¥ è¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ (token æœ‰æ•ˆæœŸåªæœ‰24å°æ—¶)
kubeadm join 192.168.0.135:6443 --token c0bvoz.hgl73sk67hby5k8y \
    --discovery-token-ca-cert-hash sha256:abfc5fce397a488c224bf6e44c5a95dc44e1e3bf06e348f9c0675bfb633df647

## å¦‚æœæƒ³ç”Ÿæˆæ°¸ä¹…ç”Ÿæ•ˆçš„ token è¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ ç”Ÿæˆï¼š
kubectl token create --ttl 0	# ç”¨æ°¸ä¹…çš„tokenå€¼ æ›¿æ¢æˆ æœ‰é™æœŸçš„tokenå€¼ ä½ çš„node å¯ä»¥åœ¨ä»»ä½•æ—¶é—´ç‚¹æ¥åŠ å…¥é›†ç¾¤
```
![[Pasted image 20240131202433.png]]

ç”±äºæ²¡æœ‰å®‰è£…ç½‘ç»œæ’ä»¶ å¯ä»¥çœ‹åˆ°nodeçš„çŠ¶æ€æ˜¯ NotReadyçš„

ä»¥åŠcoredns å¤„äºpendingçŠ¶æ€
![[Pasted image 20240131202438.png]]

# äº”ã€å®‰è£…ç½‘ç»œæ’ä»¶

flannel

calico

weave

â€¦ ç½‘ç»œæ’ä»¶åŒºåˆ« å‚è€ƒæ–‡æ¡£ï¼š[https://www.sohu.com/a/304555150_618296](https://www.sohu.com/a/304555150_618296)

å½“å‰ç¯å¢ƒä½¿ç”¨calico

## 1ã€ä¸‹è½½é…ç½®æ–‡ä»¶ï¼šä¸‹è½½calicoçš„yamlæ–‡ä»¶

wget [https://docs.projectcalico.org/manifests/calico.yaml](https://docs.projectcalico.org/manifests/calico.yaml)

## 2ã€æŸ¥çœ‹ä¸€ä¸‹Calicoç‰ˆæœ¬æ˜¯å¤šå°‘ï¼š

cat calico.yaml | grep image

æŸ¥çœ‹ä¸K8sçš„ç‰ˆæœ¬æ”¯æŒæƒ…å†µï¼š[https://docs.projectcalico.org/getting-started/kubernetes/requirements](https://docs.projectcalico.org/getting-started/kubernetes/requirements)

## 3ã€ä¿®æ”¹calico.yamlï¼š

vim calico.yaml

nameå–æ¶ˆæ³¨é‡Šå°±å¯ä»¥ï¼Œvalueæ”¹æˆç¬¬ä¸€èŠ‚çš„é…ç½®æ–‡ä»¶(kubeadm-config.yaml)é‡Œé¢çš„podSubnetã€‚

åœ¨vié‡Œé¢æœä¸€ä¸‹â€œ/192.168â€å°±å¯ä»¥æ‰¾åˆ°è¿™ä¸ªåœ°æ–¹ã€‚

## 4ã€åˆ›å»ºCalicoï¼š

kubectl apply -f calico.yaml

## 5ã€å†æ¬¡æŸ¥çœ‹K8sç»„ä»¶ï¼Œå°±å¯ä»¥çœ‹åˆ°å…¨éƒ¨èµ·æ¥äº†ï¼šï¼ˆéœ€è¦ä¸€äº›æ—¶é—´ æ‹‰å–é•œåƒæ¯”è¾ƒæ…¢ï¼‰

kubectl get pod -n kube-system
![[Pasted image 20240131202507.png]]

![[Pasted image 20240131202723.png]]

ç­‰å¾…äº†æ¯”è¾ƒä¹…çš„æ—¶é—´ calico å’Œ corednsçš„podæ‰è·‘èµ·æ¥

æ•…æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ æŸ¥çœ‹podçš„è¯¦ç»†ä¿¡æ¯

```
kubectl describe po calico-kube-controllers-69496d8b75-n82rx -n kube-system
```
![[Pasted image 20240131202734.png]]

envents å¦‚ä¸‹:

```shell
Events:
  Type     Reason                  Age                  From     Message
  ----     ------                  ----                 ----     -------
  Warning  FailedCreatePodSandBox  51m (x907 over 86m)  kubelet  (combined from similar events): Failed to create pod sandbox: rpc error: code = Unknown desc = failed to set up sandbox container "ef8d89540c967fa079a6e33bd78dbe2e35ef50ce63672e27f5cc2ebf1ab48e9a" network for pod "calico-kube-controllers-69496d8b75-n82rx": networkPlugin cni failed to set up pod "calico-kube-controllers-69496d8b75-n82rx_kube-system" network: stat /var/lib/calico/nodename: no such file or directory: check that the calico/node container is running and has mounted /var/lib/calico/
  Normal   Pulled                  43m                  kubelet  Successfully pulled image "docker.io/calico/kube-controllers:v3.18.1" in 6m38.20432903s
```

å‘ç°æ‹‰å–é•œåƒè€—æ—¶æ¯”è¾ƒä¹…
![[Pasted image 20240131202544.png]]
# å…­ã€ä½¿ç”¨å‘½ä»¤éƒ¨ç½²ä¸€ä¸ª nginx

éƒ¨ç½²nginxä¹‹å‰ è¿˜éœ€å°†master èŠ‚ç‚¹ å»é™¤ æ±¡ç‚¹ ä½¿å…¶ä¸Š ä¹Ÿèƒ½æ­£å¸¸è¿è¡Œpod
```shell
kubectl taint node master node-role.kubernetes.io/master-
```

ä»¥deploymenæ–¹å¼ èµ·pod
```shell

kubectl create deployment nginx-deployment --image=nginx --port=80

#åˆ›å»ºä¸€ä¸ªnginx podå¯¹åº”çš„ service ä»¥nodeportç±»å‹åˆ›å»º
kubectl expose deployment nginx-deployment --port=80 --target-port=80 --name=nginx-service --type=NodePort

#æŸ¥çœ‹nginx å¯¹åº”çš„nodeport
kubectl get svc|grep nginx|cut -d":" -f2|cut -d"/" -f1
```
èŠ‚ç‚¹ip + nodeport ç”¨æœ¬æœºæµè§ˆå™¨è¿›è¡Œè®¿é—®

[http://192.168.0.135:31280](http://192.168.0.135:31280)
# ä¸ƒ. éƒ¨ç½²ingress-nginx
ingress-nginx v1.0 æœ€æ–°ç‰ˆæœ¬ v1.0  
é€‚ç”¨äº Kubernetes ç‰ˆæœ¬ v1.19+ ï¼ˆåŒ…æ‹¬ v1.19 ï¼‰  
Kubernetes-v1.22+ éœ€è¦ä½¿ç”¨ ingress-nginx>=1.0ï¼Œå› ä¸º networking.k8s.io/v1beta å·²ç»ç§»é™¤

ç›´æ¥éƒ¨ç½²æ¯”è¾ƒç®€å•ï¼Œç›´æ¥æ‹‰å» girhub çš„æ–‡ä»¶å°±å¯ä»¥äº†ï¼Œå¦‚æœé‡åˆ°é•¿æ—¶é—´æ— å“åº”ï¼Œå¯ä»¥ç»ˆæ­¢ä»»åŠ¡ä»æ–°æ‹‰å–ã€‚  
æ‹‰å–é•œåƒéƒ¨åˆ†ï¼Œå¯ä»¥ä¿®æ”¹ä¸ºä¸€ä¸‹çš„é•œåƒåœ°å€

```shell
wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.0.0/deploy/static/provider/baremetal/deploy.yaml

sed -i 's@k8s.gcr.io/ingress-nginx/controller:v1.0.0\(.*\)@willdockerhub/ingress-nginx-controller:v1.0.0@' deploy.yaml
sed -i 's@k8s.gcr.io/ingress-nginx/kube-webhook-certgen:v1.0\(.*\)$@hzde0128/kube-webhook-certgen:v1.0@' deploy.yaml
kubectl apply -f ingress-nginx.yaml
```

[ğŸ“deploy.yaml](https://www.yuque.com/attachments/yuque/0/2021/yaml/750797/1639547149652-805aa1f7-9ece-459f-8052-f8e8b26aca42.yaml)

### æ£€æŸ¥å®‰è£…

Completed çŠ¶æ€çš„æ˜¯æ­£å¸¸çš„ï¼Œå¯ä»¥å¿½ç•¥ã€‚

```shell
[root@master ~]# kubectl get po -n ingress-nginx
NAME                                        READY   STATUS      RESTARTS   AGE
ingress-nginx-admission-create-pm6sw        0/1     Completed   0          22m
ingress-nginx-admission-patch-m8w94         0/1     Completed   0          22m
ingress-nginx-controller-7d4df87d89-272ft   1/1     Running     0          22m
[root@master ~]# kubectl get svc -n ingress-nginx
NAME                                 TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                      AGE
ingress-nginx-controller             NodePort    10.96.88.139   <none>        80:30497/TCP,443:32581/TCP   22m
ingress-nginx-controller-admission   ClusterIP   10.96.193.26   <none>        443/TCP                      22m
```

### åˆ›å»ºåº”ç”¨yaml

```shell
vim tomcat.yaml
```
tomcat.yamlæ–‡ä»¶å¦‚ä¸‹
```shell
apiVersion: apps/v1 
kind: Deployment   
metadata:             
  name: tomcat-deployment     
  labels:       
    app: tomcat  
spec:          
  replicas: 2 
  selector:      
    matchLabels: 
      app: tomcat
  minReadySeconds: 1
  progressDeadlineSeconds: 60
  revisionHistoryLimit: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  template:        
    metadata:  
      labels:  
        app: tomcat
    spec:         
      containers:     
      - name: tomcat     
        image: wenlongxue/tomcat:tomcat-demo-62-8fe6052    
        imagePullPolicy: Always          
        ports:
        - containerPort: 8080
        resources:
          requests:
            memory: "2Gi"
            cpu: "80m"
          limits: 
            memory: "2Gi" 
            cpu: "80m"
        readinessProbe:
          httpGet:
            path: /
            port: 8080
          initialDelaySeconds: 180
          periodSeconds: 5
          timeoutSeconds: 3
          successThreshold: 1
          failureThreshold: 30
---
apiVersion: v1
kind: Service
metadata:      
  name: tomcat-service
  labels:      
    app: tomcat 
spec:        
  selector:   
    app: tomcat  
  ports:
  - name: tomcat-port 
    protocol: TCP      
    port: 8080         
    targetPort: 8080   
  type: ClusterIP 
```

éƒ¨ç½² tomcat åº”ç”¨

```shell
kubectl  apply  -f  tomcat.yaml 
```
### åˆ›å»º ingress yaml

vim tomcat-ingress.yaml
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: tomcat
  annotations:
    kubernetes.io/ingress.class: "nginx"
spec:
  rules:
  - host: tomcat.cnsre.cn
    http:
      paths:
      - path: "/"
        pathType: Prefix
        backend:
          service:
            name: tomcat-service
            port:
              number: 8080
```

éƒ¨ç½² tomcat ingress yaml

```shell
kubectl  apply  -f  tomcat-ingress.yaml 
```

æŸ¥çœ‹ ingress å¯¹åº”èŠ‚ç‚¹çš„ç«¯å£

```shell
kubectl get svc -n ingress-nginx
NAME                                 TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                      AGE
ingress-nginx-controller             NodePort    10.96.88.139   <none>        80:30497/TCP,443:32581/TCP   54m
ingress-nginx-controller-admission   ClusterIP   10.96.193.26   <none>        443/TCP                      54m
```

### æ·»åŠ  hosts

åœ¨ hosts æ–‡ä»¶æœ€åè¿½åŠ  ingress èŠ‚ç‚¹çš„ IP åœ°å€

```
54.xxx.xxx.xxx tomcat.cnsre.cn
```

ç„¶ååœ¨æµè§ˆå™¨ä¸­è®¿é—® [tomcat.cnsre.cn:30497](https://cnsre.cn/)ã€‚

  
# é…ç½®k8sçš„å‘½ä»¤è¡¥å…¨(å¯é€‰)

```shell
cd ~
echo "source <(kubectl completion bash)" >> ~/.bash_profile
source .bash_profile
yum -y install bash-completion
source /etc/profile.d/bash_completion.sh
```
