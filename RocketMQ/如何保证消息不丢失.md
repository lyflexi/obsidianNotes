producer在发送消息的同时会向磁盘进行刷盘（硬盘），rocketmq有两种刷盘机制，同步刷盘和异步刷盘。
虽然同步刷盘可以100%解决数据丢失问题，但是效率太低，所以生产上还是会结合PageCache去实现异步刷盘
# 持久化原理
前面一直说，当消息到达RocektMQ服务端时，需要将消息存到磁盘文件
## 磁盘文件CommitLog
RocketMQ给这个存消息的文件起了一个高大上的名字：CommitLog

由于消息会很多，所以为了防止文件过大，CommitLog在物理磁盘文件上被分为多个磁盘文件，每个文件默认的固定大小是1G
![[Pasted image 20240322091843.png]]

消息在写入到文件时，除了包含消息本身的内容数据，也还会包含其它信息，比如
- 消息的Topic
- 消息所在队列的id，生产者发送消息时会携带这个队列id
- 消息生产者的ip和端口
- ...

这些数据会和消息本身按照一定的顺序同时写到CommitLog文件中
![[Pasted image 20240322091917.png]]
上图中黄色排列顺序和实际的存的内容并非实际情况，我只是举个例子
## 异步刷盘PageCache
异步刷盘的时候，为了提效都是将文件的内容先写到内核缓冲区PageCache，写到PageCache并不能保证消息一定不丢失，因为PageCache属于内存结构不稳定，如果RocketMQ服务器挂了，这部分数据是会丢失的，所以写到PageCache之后才要执行真正的异步刷盘==（这有点类似于Redis分布式锁在前面加一层库存的缓存，用于预扣减进一步提升分布式锁的性能）==

异步刷盘将消息真正的持久化到磁盘中，异步刷盘也有两种机制，是根据配置文件来决定的，二选一，默认是第一种
1. RocketMQ会开启一个后台线程，这个后台线程默认每隔0.5s会将消息从PageCache刷到磁盘中
2. 还有一种就是来一条消息触发一次刷盘，但是也是异步的，默认每次刷页，不足页就不刷，也就是说如果触发了刷盘，内存的页数少于4是不会去刷盘的，也就是仅靠靠这种刷盘机制，可能会有少于页的数据刷不到磁盘。为了彻底地将少于4页的数据刷到磁盘，默认每隔10s中就强制刷一次所有的数据到磁盘，所以理论上每隔1s中，磁盘的数据和内存中的数据是一样的
![[Pasted image 20240322092755.png]]


# 防止丢失的软策略
此外还有几种策略防止消息丢失：
1. 软策略：同一个消费者组下所有消费者实例所订阅的Topic以及Tag必须完全一致。如果订阅关系[消费者组名-Topic-Tag]不一致，会导致消费消息紊乱，甚至消息丢失。
2. 记录消息日志
	1. producer每发一次消息，都最好将发送日志保存下来，比如MySQL ，mq_log表【key，creatTime，status】初始status=0
	2. consumer每消费一条消息，也去mq_log表更新status=1
	3. 创建定时任务，每天执行，遍历mq_log中status依然为0的记录，这些记录被认为是丢失了，请求producer重新补发
	4. 因为有可能消息并没有丢失，而是挤压在了broker，所以consumer要自觉的开启幂等性判断，防止消息重复消费
3. 开启rocketmq的trace功能
	7. 在broker.conf中开启消息追踪traceTopicEnable=true，重启broker
	8. 生产者配置yml开启消息轨迹，enable-msg-trace: true
	9. 消费者开启消息轨迹功能，可以给单独的某一个消费者开启enableMsgTrace = true
	10. rocket面板可以查看某一Topic的轨迹

